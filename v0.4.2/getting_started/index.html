<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started · Stheno.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Stheno.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li class="current"><a class="toctext" href>Getting Started</a><ul class="internal"><li><a class="toctext" href="#Exact-Inference-in-a-GP-in-2-Minutes-1">Exact Inference in a GP in 2 Minutes</a></li><li><a class="toctext" href="#Fit-a-GP-with-NelderMead-in-2-Minutes-1">Fit a GP with NelderMead in 2 Minutes</a></li><li><a class="toctext" href="#Fit-a-GP-with-BFGS-in-2-minutes-1">Fit a GP with BFGS in 2 minutes</a></li><li><a class="toctext" href="#Inference-with-NUTS-in-2-minutes-1">Inference with NUTS in 2 minutes</a></li><li><a class="toctext" href="#Conclusion-1">Conclusion</a></li></ul></li><li><a class="toctext" href="../internals/">Internals</a></li><li><a class="toctext" href="../input_types/">Input Types</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Getting Started</a></li></ul><a class="edit-page" href="https://github.com/willtebbutt/Stheno.jl/blob/master/docs/src/getting_started.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Getting Started</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Getting-Started-1" href="#Getting-Started-1">Getting Started</a></h1><p>Here we document how to achieve the basic things that any GP package aught to be able to do. We lean heavily on the rest of the Julia ecosystem for each of these examples – this page really exemplifies the way in which different packages play together nicely in the Julia!</p><p>This guide assumes that you know roughly what&#39;s going on conceptually with GPs. If you&#39;re new to Gaussian processes, I cannot recommend <a href="http://videolectures.net/gpip06_mackay_gpb/">this video lecture</a> highly enough.</p><h2><a class="nav-anchor" id="Exact-Inference-in-a-GP-in-2-Minutes-1" href="#Exact-Inference-in-a-GP-in-2-Minutes-1">Exact Inference in a GP in 2 Minutes</a></h2><p>While Stheno offers some bells and whistles that other GP frameworks do not, it also offers the same functionality as a usual GP framework.</p><pre><code class="language-julia">using Stheno

# Choose the length-scale and variance of the process.
l = 0.4
σ² = 1.3

# Construct a kernel with this variance and length scale.
k = σ² * stretch(matern52(), 1 / l)

# Specify a zero-mean GP with this kernel. Don&#39;t worry about the GPC object.
f = GP(k, GPC())

# Generate a sample from this GP at some random input locations.
# Add some iid observation noise, with zero-mean and variance 0.05.
const x = randn(100)
σ²_n = 0.05
fx = f(x, σ²_n)
const y = rand(fx)

# Compute the log marginal likelihood of this observation, just because we can.
logpdf(fx, y)</code></pre><p><code>fx</code> should be thought of as &quot;<code>f</code> at <code>x</code>&quot;, and is just as a multivariate Normal distribution, with zero mean and covariance matrix</p><pre><code class="language-julia">Stheno.pairwise(k, x) + σ² * I</code></pre><p>As such samples can be drawn from it, and the log probability any particular value under it can be computed, in the same way that you would an <code>MvNormal</code> from <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a>.</p><p>We can visualise <code>x</code> and <code>y</code> with <a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a></p><pre><code class="language-julia">using Plots
plt = plot();
scatter!(plt, x, y; color=:red, label=&quot;&quot;);
display(plt);</code></pre><p><img src="https://willtebbutt.github.io/resources/samples.svg" alt="img"/></p><p>It&#39;s straightforward to compute the posterior over <code>f</code>:</p><pre><code class="language-julia">f_posterior = f | Obs(fx, y)</code></pre><p><code>f_posterior</code> is another GP, the posterior over <code>f</code> given noisy observations <code>y</code> at inputs <code>x</code>. Equivalently:</p><pre><code class="language-julia">f_posterior = f | (fx ← y) # ← is \leftarrow[TAB]</code></pre><p>This is just syntactic sugar for the above. You can use it, or not, the choice is entirely your own.</p><p><a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a> knows how to plot GPs, so it&#39;s straightforward to look at the posterior:</p><pre><code class="language-julia">x_plot = range(-4.0, 4.0; length=1000);
plot!(plt, f_posterior(x_plot); samples=10, label=&quot;&quot;, color=:blue);
display(plt);</code></pre><p><img src="https://willtebbutt.github.io/resources/samples_posterior.svg" alt="img"/></p><h2><a class="nav-anchor" id="Fit-a-GP-with-NelderMead-in-2-Minutes-1" href="#Fit-a-GP-with-NelderMead-in-2-Minutes-1">Fit a GP with NelderMead in 2 Minutes</a></h2><p>Stheno.jl is slightly unusual in that it declines to provide a <code>fit</code> or <code>train</code> function. Why is this? In short, because it&#39;s hard to design a one-size-fits-all interface for training a GP that composes well with the rest of the tools in the Julia ecosystem, and you <em>really</em> want to avoid creating any impediments to interacting with other tools in the ecosystem.</p><p>Here we demonstrate the simplest most low-level way to work with Stheno, in which everything is done manually. This example is to demonstrate that the previous section provides all of the basic building blocks that you <em>need</em> to solve regression problems with GPs.</p><pre><code class="language-julia">function unpack(θ)
    σ² = exp(θ[1]) + 1e-6
    l = exp(θ[2]) + 1e-6
    σ²_n = exp(θ[3]) + 1e-6
    return σ², l, σ²_n
end

# nlml = negative log marginal likelihood (of θ)
function nlml(θ)
    σ², l, σ²_n = unpack(θ)
    k = σ² * stretch(matern52(), 1 / l)
    f = GP(k, GPC())
    return -logpdf(f(x, σ²_n), y)
end</code></pre><p>Hopefully it&#39;s clear what we mean by low-level here. We&#39;ve manually defined a function to unpack a parameter vector <code>θ</code> and use this to construct a function that computes the log marginal probability of <code>y</code> for any particular <code>θ</code>. We can use a gradient-free optimisation technique from <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> to find the parameters whose log marginal likelihood is minimal:</p><pre><code class="language-julia">using Optim
θ0 = randn(3);
results = Optim.optimize(nlml, θ0, NelderMead())
σ²_ml, l_ml, σ²_n_ml = unpack(results.minimizer);</code></pre><p>We can now use this to construct the posterior GP and look at the posterior in comparison to the true posterior with the known hyperparameters</p><pre><code class="language-julia">k = σ²_ml * stretch(matern52(), 1 / l_ml);
f = GP(k, GPC());
f_posterior_ml = f | Obs(f(x, σ²_n_ml), y);
plot!(plt, f_posterior_ml(x_plot); samples=10, color=:green, label=&quot;&quot;);
display(plt);</code></pre><p><img src="https://willtebbutt.github.io/resources/samples_posterior_both.svg" alt="img"/></p><p>(Of course the exact posterior has not been recovered because the exact hyperparameters cannot be expected to be recovered.)</p><h2><a class="nav-anchor" id="Fit-a-GP-with-BFGS-in-2-minutes-1" href="#Fit-a-GP-with-BFGS-in-2-minutes-1">Fit a GP with BFGS in 2 minutes</a></h2><p>The BFGS algorithm is generally the preferred choice when optimising the hyperparameters of fairly simple GPs. It requires access to the gradient of our <code>nlml</code> function, which can be straightforwardly obtained via reverse-mode algorithmic differentiation, which is provided by <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a>:</p><pre><code class="language-julia">using Zygote: gradient
θ0 = randn(3);
results = Optim.optimize(nlml, θ-&gt;gradient(nlml, θ)[1], θ0, BFGS(); inplace=false)
σ²_bfgs, l_bfgs, σ²_n_bfgs = unpack(results.minimizer);</code></pre><p>Once more visualising the results:</p><pre><code class="language-julia">k = σ²_bfgs * stretch(matern52(), 1 / l_bfgs);
f = GP(k, GPC());
f_posterior_bfgs = f | Obs(f(x, σ²_n_bfgs), y);
plot!(plt, f_posterior_bfgs(x_plot); samples=10, color=:purple, label=&quot;&quot;);
display(plt);</code></pre><p><img src="https://willtebbutt.github.io/resources/samples_posterior_bfgs.svg" alt="img"/></p><p>Notice that the two optimisers produce (almost) indistinguishable results.</p><h2><a class="nav-anchor" id="Inference-with-NUTS-in-2-minutes-1" href="#Inference-with-NUTS-in-2-minutes-1">Inference with NUTS in 2 minutes</a></h2><p><a href="https://github.com/TuringLang/AdvancedHMC.jl/">AdvancedHMC.jl</a> provides a state-of-the-art implementation of the No-U-Turns sampler, which we can use to perform approximate Bayesian inference in the hyperparameters of the GP. This is slightly longer than the previous examples, but it&#39;s all set up associated with AdvancedHMC, which is literally a copy-paste from that package&#39;s README:</p><pre><code class="language-julia">using AdvancedHMC, Zygote

# Define the log marginal likelihood function and its gradient
ℓπ(θ) = -nlml(θ)
function ∂ℓπ∂θ(θ)
    lml, back = Zygote.forward(ℓπ, θ)
    ∂θ = first(back(1.0))
    return lml, ∂θ
end

# Sampling parameter settings
n_samples, n_adapts = 100, 20

# Draw a random starting points
θ0 = randn(3)

# Define metric space, Hamiltonian, sampling method and adaptor
metric = DiagEuclideanMetric(3)
h = Hamiltonian(metric, ℓπ, ∂ℓπ∂θ)
int = Leapfrog(find_good_eps(h, θ0))
prop = NUTS{MultinomialST, GeneralisedNoUTurn}(int)
adaptor = StanHMCAdaptor(n_adapts, Preconditioner(metric), NesterovDualAveraging(0.8, int.ϵ))

# Perform inference
samples, stats = sample(h, prop, θ0, n_samples, adaptor, n_adapts; progress=true)

# Inspect posterior distribution over hyperparameters.
hypers = unpack.(samples);
plt_hypers = plot();
plot!(plt_hypers, getindex.(hypers, 1); label=&quot;variance&quot;);
plot!(plt_hypers, getindex.(hypers, 2); label=&quot;length scale&quot;);
plot!(plt_hypers, getindex.(hypers, 3); label=&quot;obs noise variance&quot;);
display(plt_hypers);</code></pre><p><img src="https://willtebbutt.github.io/resources/posterior_hypers.svg" alt="img"/></p><p>As expected, the sampler converges to the posterior distribution quickly. One could combine this code with that from the previous sections to make predictions under the posterior over the hyperparameters.</p><p>Also note that we didn&#39;t specify a prior over the kernel parameters in this example, so essentially used an improper prior. We could have used a proper prior by appropriately modifying <code>ℓπ</code>.</p><h2><a class="nav-anchor" id="Conclusion-1" href="#Conclusion-1">Conclusion</a></h2><p>That&#39;s it! You now know how to do typical GP stuff in Stheno. In particular how to:</p><ul><li>specify a kernel with a particular length-scale and variance</li><li>construct a GP</li><li>sample from a GP, and specify an observation noise</li><li>compute the log marginal likelihood of some observations</li><li>visualise a simple 1D example</li><li>infer kernel parameters in a variety of ways</li></ul><p>We <em>haven&#39;t</em> covered any of the fancy features of Stheno yet though.</p><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../internals/"><span class="direction">Next</span><span class="title">Internals</span></a></footer></article></body></html>
