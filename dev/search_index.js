var documenterSearchIndex = {"docs":
[{"location":"#Stheno.jl-1","page":"Home","title":"Stheno.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Stheno.jl is a package for probabilistic programming with Gaussian processes.","category":"page"},{"location":"internals/#Interfaces-1","page":"Internals","title":"Interfaces","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"The primary objects in Stheno are AbstractGPs, which represent Gaussian processes. There are two primary concrete subtypes of AbstractGP:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"GP: an atomic Gaussian process, whose MeanFunction and Kernel are specified directly.\nCompositeGP: a Gaussian process composed of other AbstractGPs, whose properties are determined recursively from the AbstractGPs of which it is composed.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"This documentation provides the information necessary to understand the internals of Stheno, and to extend it with your own custom functionality.","category":"page"},{"location":"internals/#AbstractGP-1","page":"Internals","title":"AbstractGP","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"The AbstractGP interface enables one to compute quantities required when working with Gaussian processes in practice, namely to compute their logpdf and sample from them at particular locations in their domain.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Function Brief description\nmean_vector(f, x) The mean vector of f at inputs x\ncov(f, x) covariance matrix of f at inputs x\ncov(f, x, x′) covariance matrix between f at x and x′\ncov(f, f′, x, x′) cross-covariance matrix between f at x and f′ at x′","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"It should always hold that cov(f, x) ≈ cov(f, f, x, x), but in some important cases cov(f, x) will be significantly faster.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"GP and CompositGP are concrete subtypes of AbstractGP, and can be found here","category":"page"},{"location":"internals/#diag-methods-1","page":"Internals","title":"diag methods","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"It is crucial for pseudo-point methods, and for the computation of marginal statistics at a reasonable scale, to be able to compute the diagonal of a given covariance matrix in linear time in the size of its inputs. This in turn necessitates that the diagonal of a given cross-covariance matrix can also be computed efficiently as the evaluation of covariance matrices often rely on the evaluation of cross-covariance matrices. As such, we have the following functions:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Function Brief description\ncov_diag(f, x) diag(cov(f, x))\ncov_diag(f, x, x′) diag(cov(f, x, x′))\ncov_diag(f, f′, x, x′) diag(cov(f, f′, x, x′))","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"The second and third rows of the table only make sense when length(x) == length(x′) of course.","category":"page"},{"location":"internals/#GP-1","page":"Internals","title":"GP","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"A GP is constructed in the following manner:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"GP(m, k, gpc)","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"where m is its MeanFunction, k its Kernel. gpc is a GPC object that handles some book-keeping, and will be discussed in more depth later (don't worry it's very straightforward, and only mildly annoying).","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"The AbstractGP interface is implemented for GPs via operations on their MeanFunction and Kernel. It is therefore straightforward to extend the range of functionality offered by Stheno.jl by simply implementing a new MeanFunction or Kernel which satisfies their interface, which we detail below.","category":"page"},{"location":"internals/#MeanFunctions-1","page":"Internals","title":"MeanFunctions","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"MeanFunctions are unary functions with Real-valued outputs with a single-method interface. They must implement elementwise (aliased to ew for brevity) with the signature","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"ew(m::MyMeanFunction, x::AbstractVector)","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"This applies the MeanFunction to each element of x, and should return an AbstractVector{<:Real} of the same length as x. Some example implementations can be found here.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Note that while MeanFunctions are in principle functions, their interface does not require that we can evaluate m(x[p]), only that the \"vectorised\" elementwise function be implemented. This is due to the fact that, in practice, we only ever need the result of elementwise.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"There are a couple of methods of GP which are specialised to particular MeanFunctions:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"GP(k, gpc) == GP(ZeroMean(), k, gpc)\nGP(c, k, gpc) == GP(ConstMean(c), k, gpc) # c<:Real","category":"page"},{"location":"internals/#Kernels-1","page":"Internals","title":"Kernels","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"A Kernel is a binary function, returning a Real-valued result. Kernels are only slightly more complicated than MeanFunctions, having a four-method interface:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"# Binary methods\new(k::MyKernel, x::AbstractVector, x′::AbstractVector) # \"Binary elementwise\"\npw(k::MyKernel, x::AbstractVector, x′::AbstractVector) # \"Binary pairwise\"\n\n# Unary methods\new(k::MyKernel, x::AbstractVector) # \"Unary elementwise\"\npw(k::MyKernel, x::AbstractVector) # \"Unary pairwise\"","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Again, ew === elementwise and pw === pairwise.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Note that, as with MeanFunctions, the Kernel interface does not require that one can actually evaluate k(x[p], x′[q]), as in practice this functionality is never required.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"We consider each method in turn.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Binary elementwise: compute k(x[p], x′[p]) for p in eachindex(x). x and x′ are assumed to be of the same length. Returns a subtype of AbstractVector{<:Real}, of the same length as x and x′.\nBinary pairwiise: compute k(x[p], x′[q]) for p in eachindex(x) and q in eachindex(x′). x and x′ need not be of the same length. Returns a subtype of AbstractMatrix{<:Real} whose size is (length(x), length(x′)).\nUnary elementwise: compute k(x[p], x[p]) for p in eachindex(x). Returns a subtype of AbstractVector{<:Real} of the same length as x.\nUnary pairwise: compute k(x[p], x[q]) for p in eachindex(x) and q in eachindex(x). Returns a subtype of AbstractMatrix{<:Real} whose size is (length(x), length(x)). Crucially, output must be positive definite and (approximately) symmetric.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Example implementations can be found here. Often you'll find that multiple versions of each method are implemented, specialised to different input types. For example the EQ kernel has (at the time of writing) two implementations of each method, one for inputs AbstractVector{<:Real}, and one for ColsAreObs <: AbstractVector inputs. These specialisations are for performance purposes.","category":"page"},{"location":"internals/#CompositeGP-1","page":"Internals","title":"CompositeGP","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"CompositeGPs are constructed as affine transformations of CompositeGPs and GPs. We describe implemented transformations below.","category":"page"},{"location":"internals/#addition-1","page":"Internals","title":"addition","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Given AbstractGPs f and g, we define","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"h = f + g","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"to be the CompositeGP sastisfying h(x) = f(x) + g(x) for all x. ","category":"page"},{"location":"internals/#multiplication-1","page":"Internals","title":"multiplication","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Multiplication of AbstractGPs is undefined since the product of two Gaussian random variables is not itself Gaussian. However, we can scale an AbstractGP by either a constant or (deterministic) function.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"h = c * f\nh = sin * f","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"will both work, and produce the result that h(x) = c * f(x) or h(x) = sin(x) * f(x).    ","category":"page"},{"location":"internals/#composition-1","page":"Internals","title":"composition","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"h = f ∘ g","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"for some deterministic function g is the composition of f with g. i.e. h(x) = f(g(x)).","category":"page"},{"location":"internals/#conditioning-1","page":"Internals","title":"conditioning","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"h = g | (f(x) ← y)","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"should be read as h is the posterior process produced by conditioning the process g on having observed f at inputs x to take values y.","category":"page"},{"location":"internals/#approximate-conditioning-1","page":"Internals","title":"approximate conditioning","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"TODO (implemented, not documented)","category":"page"},{"location":"internals/#cross-1","page":"Internals","title":"cross","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"TODO (implemented, not documented)","category":"page"},{"location":"internals/#GPC-1","page":"Internals","title":"GPC","text":"","category":"section"},{"location":"internals/#","page":"Internals","title":"Internals","text":"This book-keeping object doesn't matter from a user's perspective but, unfortunately, we currently expose it to users. Fortunately, it's very simple to work with. Say you wish to construct a collection of processes:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"# THIS WON'T WORK\nf = GP(mf, kf)\ng = GP(mg, kg)\nh = f + g\n# THIS WON'T WORK","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"You should actually write","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"# THIS IS GOOD. PLEASE DO THIS\ngpc = GPC()\nf = GP(mf, kf, gpc)\ng = GP(mg, kg, gpc)\nh = f + g\n# THIS IS GOOD. PLEASE DO THIS","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"The rule is simple: when constructing GP objects that you plan to make interact later in your programme, construct them using the same gpc object. For example, DON'T do the following:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"# THIS IS BAD. PLEASE DON'T DO THIS\nf = GP(mf, kf, GPC())\ng = GP(mg, kg, GPC())\nh = f + g\n# THIS IS BAD. PLEASE DON'T DO THIS","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"The mistake here is to construct a separate GPC object for each GP. This will hopefully error, but might yield incorrect results.","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"Alternatively, if you're willing to place your model in a function you can write something like:","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"@model function foo(some arguments)\n    f1 = GP(mean, kernel)\n    f2 = GP(some other mean, some other kernel)\n    return f1, f2\nend","category":"page"},{"location":"internals/#","page":"Internals","title":"Internals","text":"The @model macro just places a GPC on the first line of the function and provides it as an argument to each GP constructed. Suggestions for ways to improve / extend this interface are greatly appreciated.","category":"page"}]
}
